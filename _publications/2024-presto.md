---
title: "Presto! Distilling Steps and Layers for Accelerating Music Generation"
collection: publications
permalink: /publication/presto
authors: Zachary Novack, Ge Zhu, Jonah Casebeer, Julian McAuley, Taylor Berg-Kirkpatrick, Nicholas J. Bryan
excerpt: 'This work presents Presto!, a new method for accelerating audio-domain TTM models, which works by distilling the model to drop both diffusion steps and interior layers of the model itself, achieving <0.5s for generating 32s of 44.1kHz stereo audio.'
date: 2025-01-22
venue: ['International Conference on Learning Representations (ICLR), 2025']
# venue: ['International Conference on Learning Representations (ICLR), 2023', 'Spotlight at NeurIPS Workshop on The Benefits of Higher-Order Optimization in Machine Learning, 2022']
paperurl: 'https://arxiv.org/abs/2410.05167'
# code: 'https://github.com/pnlong/PDMX'
abs_title: presto_2025_abs
bib_title: presto_2025_bib
pub_status: 'conference'
website: 'https://presto-music.github.io/web/'
citation: '@inproceedings{Novack2025Presto,<br />
    title={Presto! Distilling steps and layers for accelerating music generation.}, <br />
    author={Zachary Novack and Ge Zhu and Jonah Casebeer and <br />
            Julian McAuley and Taylor Berg-Kirkpatrick and Nicholas J. Bryan}, <br />
    year={2025}, <br />
    booktitle={International Conference on Learning Representations (ICLR)},<br />
}'
---