---
title: "Disentangling the Mechanisms Behind Implicit Regularization in SGD"
collection: publications
permalink: /publication/disentangling
excerpt: 'This work presents a comparative empirical study of different gradient norm-based regularizers for improving Large-Batch Stochastic Gradient Descent, and ties this behavior to the trajectory of the micro-batch gradient norm during training.'
date: 2022-11-29
venue: ['International Conference on Learning Representations (ICLR), 2023', 'Spotlight at NeurIPS Workshop on The Benefits of Higher-Order Optimization in Machine Learning, 2022']
paperurl: 'https://arxiv.org/abs/2211.15853'
code: 'https://github.com/acmi-lab/imp-regularizers'
abs_title: disen_2023_abs
bib_title: disen_2023_bib
citation: '@inproceedings{novack2023disentangling,
title={Disentangling the Mechanisms Behind Implicit Regularization in SGD},
author={Novack, Zachary and Kaur, Simran and Marwah, Tanya and Garg, Saurabh and Lipton, Zachary,
booktitle={International Conference on Learning Representations (ICLR)},
year={2023} }'
---